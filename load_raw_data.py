#!/usr/bin/env python3
"""
æ‰¹é‡è¯»å– raw_data æ•°æ®
=======================

ä¸€æ¬¡æ€§è¯»å–æœ€è¿‘ N å¤©çš„æ‰€æœ‰è‚¡ç¥¨ 15m K çº¿æ•°æ®

Usage:
    python load_raw_data.py --days 7
    python load_raw_data.py --days 7 --output data/combined_data.json
"""

import os
import json
import argparse
from datetime import date, timedelta
from pathlib import Path
from typing import Dict, List, Any
import pandas as pd


def get_trading_days(raw_data_path: str, n_days: int) -> List[str]:
    """è·å–æœ€è¿‘ N ä¸ªäº¤æ˜“æ—¥"""
    dates = sorted([
        d for d in os.listdir(raw_data_path)
        if os.path.isdir(os.path.join(raw_data_path, d)) and d.startswith('202')
    ], reverse=True)
    return dates[:n_days]


def load_all_raw_data(
    raw_data_path: str = "data/raw_data",
    n_days: int = 7
) -> Dict[str, Dict[str, Any]]:
    """
    æ‰¹é‡è¯»å– raw_data
    
    Returns:
        {
            "2026-01-09": {
                "AAPL": {"bars": [...], "count": 26},
                "TSLA": {"bars": [...], "count": 26},
                ...
            },
            ...
        }
    """
    trading_days = get_trading_days(raw_data_path, n_days)
    
    print(f"ğŸ“Š è¯»å–æœ€è¿‘ {len(trading_days)} ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®...")
    print(f"   æ—¥æœŸèŒƒå›´: {trading_days[-1]} ~ {trading_days[0]}")
    print(f"   ç­›é€‰æ—¶é—´: 09:30 - 16:00 (ET)")
    
    all_data = {}
    total_files = 0
    total_bars = 0
    
    # ET æ—¶åŒº
    from zoneinfo import ZoneInfo
    ET = ZoneInfo("America/New_York")
    MARKET_OPEN = 9 * 60 + 30  # 9:30 in minutes
    MARKET_CLOSE = 16 * 60     # 16:00 in minutes
    
    for day_str in trading_days:
        day_path = os.path.join(raw_data_path, day_str)
        day_data = {}
        
        files = [f for f in os.listdir(day_path) if f.endswith('_15m.json')]
        
        for filename in files:
            symbol = filename.replace('_15m.json', '')
            filepath = os.path.join(day_path, filename)
            
            try:
                with open(filepath, 'r') as f:
                    file_content = json.load(f)
                    raw_bars = file_content if isinstance(file_content, list) else file_content.get('bars', [])
                    
                    filtered_bars = []
                    for bar in raw_bars:
                        # è·å–æ—¶é—´æˆ³ string
                        ts_str = bar.get('timestamp') or bar.get('t')
                        if not ts_str:
                            continue
                            
                        # è§£ææ—¶é—´å¹¶è½¬æ¢æ—¶åŒº
                        ts = pd.to_datetime(ts_str)
                        if ts.tz is None:
                            # å­˜å‚¨çš„æ—¶é—´å·²ç»æ˜¯ ETï¼Œç›´æ¥æœ¬åœ°åŒ–ä¸º ET
                            ts_et = ts.tz_localize(ET)
                        else:
                            ts_et = ts.tz_convert(ET)
                        
                        # è®¡ç®—åˆ†é’Ÿæ•° (from midnight)
                        minutes = ts_et.hour * 60 + ts_et.minute
                        
                        # ç­›é€‰ 09:30 <= time < 16:00 (15:45 bar covers 15:45-16:00)
                        if MARKET_OPEN <= minutes < MARKET_CLOSE:
                            # ç»Ÿä¸€æ ¼å¼åŒ–æ—¶é—´
                            bar_copy = bar.copy()
                            bar_copy['timestamp'] = ts_et.strftime('%Y-%m-%d %H:%M:%S')
                            filtered_bars.append(bar_copy)
                    
                    if filtered_bars:
                        day_data[symbol] = {
                            "bars": filtered_bars,
                            "count": len(filtered_bars)
                        }
                        total_bars += len(filtered_bars)
                        total_files += 1
            except Exception as e:
                print(f"  âš ï¸ è¯»å–å¤±è´¥: {filepath}: {e}")
        
        all_data[day_str] = day_data
        print(f"  âœ… {day_str}: {len(day_data)} åªè‚¡ç¥¨ (ET 09:30-16:00)")
    
    print(f"\nğŸ“ˆ è¯»å–å®Œæˆ!")
    print(f"   æ–‡ä»¶æ•°: {total_files}")
    print(f"   Kçº¿æ€»æ•°: {total_bars:,}")
    print(f"   è‚¡ç¥¨æ•°: {len(set(s for d in all_data.values() for s in d.keys()))}")
    
    return all_data


def to_dataframe(all_data: Dict) -> pd.DataFrame:
    """è½¬æ¢ä¸º DataFrame æ ¼å¼"""
    records = []
    
    for day_str, day_data in all_data.items():
        for symbol, data in day_data.items():
            for bar in data['bars']:
                records.append({
                    'date': day_str,
                    'symbol': symbol,
                    'timestamp': bar.get('timestamp'),
                    'open': bar.get('open'),
                    'high': bar.get('high'),
                    'low': bar.get('low'),
                    'close': bar.get('close'),
                    'volume': bar.get('volume')
                })
    
    df = pd.DataFrame(records)
    return df


def main():
    parser = argparse.ArgumentParser(description="æ‰¹é‡è¯»å– raw_data")
    parser.add_argument("--days", type=int, default=7, help="è¯»å–æœ€è¿‘ N å¤©æ•°æ®")
    parser.add_argument("--output", type=str, help="è¾“å‡º JSON æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--csv", type=str, help="è¾“å‡º CSV æ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    # è¯»å–æ•°æ®
    all_data = load_all_raw_data(n_days=args.days)
    
    # è¾“å‡º JSON
    if args.output:
        with open(args.output, 'w') as f:
            json.dump(all_data, f, indent=2)
        print(f"\nğŸ’¾ å·²ä¿å­˜: {args.output}")
    
    # è¾“å‡º CSV
    if args.csv:
        df = to_dataframe(all_data)
        df.to_csv(args.csv, index=False)
        print(f"ğŸ’¾ å·²ä¿å­˜: {args.csv}")
    
    # è¿”å›ç»Ÿè®¡
    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    for day_str, day_data in sorted(all_data.items()):
        total_bars = sum(d['count'] for d in day_data.values())
        print(f"   {day_str}: {len(day_data)} è‚¡ç¥¨, {total_bars} Kçº¿")


if __name__ == "__main__":
    main()
